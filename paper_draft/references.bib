@inproceedings{yin2024should,
    title={Should We Respect {LLMs}? A Cross-Lingual Study on the Influence of Prompt Politeness on {LLM} Performance},
    author={Yin, Ziqi and Wang, Hao and Horio, Kaito and Kawahara, Daisuke and Sekine, Satoshi},
    booktitle={Proceedings of the 3rd Workshop on Social Influence in Conversations (SICon 2024)},
    year={2024}
}

@article{dobariya2025mind,
    title={Mind Your Tone: An Exploration of Rude vs. Polite Prompting in ChatGPT},
    author={Dobariya, Om and Kumar, Akhil},
    journal={arXiv preprint arXiv:2510.04950},
    year={2025}
}

@article{cai2025does,
    title={Does Tone Change the Answer? Evaluating {LLM} Sensitivity to Politeness Across Models, Tasks, and Scales},
    author={Cai, Hanyu and Shen, Binqi and Jin, Lier and Hu, Lan and Fan, Xiaojing},
    journal={arXiv preprint arXiv:2512.12812},
    year={2025}
}

@article{li2023emotionprompt,
    title={{EmotionPrompt}: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus},
    author={Li, Cheng and Wang, Jindong and Zhang, Yixuan and Zhu, Kaijie and Hou, Wenxin and Lian, Jianxun and Luo, Fang and Yang, Qiang and Xie, Xing},
    journal={arXiv preprint arXiv:2307.11760},
    year={2023}
}

@inproceedings{wang2024negativeprompt,
    title={Large Language Models Are Not Yet Human-Level Evaluators for Abstractive Summarization},
    author={Wang, Xu and Li, Cheng and Chang, Yi and Wang, Jindong and Wu, Yuan},
    booktitle={Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)},
    note={NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli. arXiv:2405.02814},
    year={2024}
}

@article{bsharat2023principled,
    title={Principled Instructions Are All You Need for Questioning {LLaMA-1/2, GPT-3.5/4}},
    author={Bsharat, Sondos Mahmoud and Myrzakhan, Aidar and Shen, Zhiqiang},
    journal={arXiv preprint arXiv:2312.16171},
    year={2023}
}

@article{gandhi2025prompt,
    title={Prompt Sentiment: The Catalyst for {LLM} Change},
    author={Gandhi, Vishal and Gandhi, Sagar},
    journal={arXiv preprint arXiv:2503.13510},
    year={2025}
}

@article{hendrycks2021measuring,
    title={Measuring Massive Multitask Language Understanding},
    author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
    journal={Proceedings of the International Conference on Learning Representations (ICLR)},
    year={2021}
}

@article{lin2022truthfulqa,
    title={{TruthfulQA}: Measuring How Models Mimic Human Falsehoods},
    author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
    journal={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL)},
    year={2022}
}
